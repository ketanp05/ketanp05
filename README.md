# üí´ About Me:
Ketan is a user-centric engineer with expertise in developing robust solutions using languages like Python, Javascript, and C++ and frameworks such as Flask, FastAPI, React.js, Next.js, Express.js, Node.js and Vue.js. He is proficient in utilizing databases like MySQL, SQLite, MongoDB, and PostgreSQL. With full-stack development experience, Ketan has leveraged Python for backend services and Vue.js for dynamic, user-friendly frontends. He excels in building end-to-end data pipelines, optimizing data profiling features, and developing real-time data processing pipelines with tools like Apache Spark, Kafka, SQL, and Azure Databricks. His role as an Systems Analyst involved developing a Manufacturing Execution System (MES) using Tulip, enhancing real-time data collection, process optimization, and operational efficiency.

Graduated in Spring 2024 in Computer Science, Ketan is currently a Machine Learning Engineer at Michigan Tech's Department of Mechanical Engineering - Engineering Mechanics, focusing on advancing real-time fault diagnosis and prognosis in machinery systems.

Additionally, Ketan is enhancing his knowledge/skills by tackling algorithmic challenges on Leetcode and engaging in comprehensive courses covering essential tools and technologies in ML, followed by building end-to-end data pipelines and projects incorporating best software engineering practices.

At Milwaukee Tool, my role as an IT Analyst allowed me to lead the development of applications improving assembly operations and to document software requirements for enhancements. My efforts in data visualization significantly optimized manufacturing processes, highlighting my capacity to deliver technical solutions with a tangible impact on business efficiency and profitability. During my tenure at UST, I was instrumental in developing the Data Catalog feature for the proprietary ETL Framework "Pine," showcasing my proficiency in Python, SQL, and cloud technologies like AWS, and Azure, and underlining my holistic approach to software and data engineering that spans both client-facing and backend systems.<br><br>What do I bring on the table:<br>‚Ä¢ Solid background in software/data engineering, focused on backend development, database management, and data pipelines.<br>‚Ä¢ Experience in machine learning, process automation, data workflow optimization, and scalable cloud solutions.<br>‚Ä¢ A strong interest and foundation in aligning technological innovations with strategic business objectives.<br>‚Ä¢ A commitment to continuous improvement!

**Ketan is actively seeking opportunities to apply his diverse skill set in Software Engineering (Backend), Data Engineering, Data Science (Machine Learning), Analyst(IT/MES/Manufacturing/Business) with the goal of contributing to innovative projects that leverage cutting-edge technologies and deliver significant business value.**

# üè¢ Work Experience:

## üîß [Milwaukee Tool](https://www.milwaukeetool.com)
At Milwaukee Tool, I spearheaded the development of a Pick-To-Light Manufacturing Execution System (MES) using Tulip and REST APIs. This innovative system guided operators on both what to build and how to build it, effectively controlling the assembly process and integrating with the plant-wide messaging and alarm system for seamless interaction and documentation. Leveraging my coursework in Human-Computer Interaction and Usability Testing from Michigan Tech, I designed intuitive user interfaces and developed key performance indicators (KPIs) using SQL, such as cycle time, defect rate, and throughput, resulting in a 35% boost in assembly process efficiency. My role also involved authoring a Functional Requirements Document (FRD) for the FreedomOEE tool, ensuring clarity and accuracy in specifications, which helped fast-track the resolution of timely alert issues. Additionally, I designed data visualization charts to analyze key OEE metrics, leading to a 500-unit increase in monthly production output and a reduction of production errors by 20 incidents per week, significantly enhancing operational efficiency.

## üí° [UST AlphaAI](https://www.ust.com/en/alpha-ai)
At UST AlphaAI, I implemented 5 REST APIs for a custom ETL tool using Vue.js, Flask, and MySQL, integrating JWT for secure authentication and CRUD operations to store pipeline metadata, which resulted in a 40% boost in data workflow efficiency. I significantly improved development efficiency by migrating the Vue.js frontend from the data ingestion framework to the ETL tool, reducing a typical 3-month migration timeline to just 1 month. I also refactored the data cataloging feature using PySpark and Databricks Koalas, achieving a 60% increase in processing efficiency and reducing runtime from 10 hours to 4 hours. Additionally, I engineered a real-time data pipeline with Azure Stack (Stream Analytics, Databricks), Apache tools (Kafka, Superset), and Snowflake, which reduced data latency by 30% and enabled timely extraction of 5 key business metrics.

## üñ•Ô∏è [Humane Interface Design Enterprise (HIDE)](http://hide.cs.mtu.edu)

### üë®‚Äçüíª Software Development Engineer (SDE)
At HIDE, I significantly improved the deployment efficiency of a Django application on cPanel by 10%, configuring WSGI and securing the production environment. I integrated Microsoft Authentication Library (MSAL) for token acquisition using Postman and Azure, ensuring secure and efficient access control through Azure Active Directory integrations. I developed a documentation platform for HIDE projects, achieving a 90% Web Accessibility rating by leveraging web design best practices and creating detailed technical guides. Additionally, I architected and recommended technology stacks, including programming languages, frameworks, and databases, fostering collaboration across teams and ensuring efficient development.

### üìä Process Analyst
As an Agile Process Analyst for the Little Brothers Friends of the Elderly (LBFE) development team, I led efforts to streamline scheduling and manage transportation services, optimizing the utilization of vehicles and volunteers. I improved the team's process efficiency by 30%, reducing the backlog through the integration and optimization of Trello and Discord for task management and communication. I increased the technical skill level of team members from an average of 2 to 3 (on a 5-point scale) over a semester by introducing pair programming and technical workshops. I also enhanced the client interaction process by organizing bi-weekly presentations and reviews, significantly improving the quality of project updates and feedback sessions.

## üéì [Michigan Technological University](https://www.mtu.edu)

### üß¨ Research Assistant (Computational Genomics)
As a Graduate Research Assistant under Dr. Hairong Wei, I conducted in-depth research on genome sequencing, focusing on techniques, genome analysis, and the role of k-mers. I utilized bioinformatics software such as Bioconda, KMC, and Jellyfish for genomic data processing. I managed server interactions via UNIX, using commands for server connections, file upload/download, and executing Python scripts to ensure efficient data handling. Additionally, I debugged Python scripts for staging .fastqc files, streamlining data preparation for genome analysis. My work included exploring Explainable AI (xAI), specifically SHAP, to interpret deep learning models, contributing to the understanding of gene contributions to COVID-19.

### üñºÔ∏è Research Assistant (Medical Image Segmentation)
As a Graduate Research Assistant for Dr. Sidike Paheding in the Machine Intelligence (MAIN) Group, I assisted in developing, programming, testing, and documenting U-Net and its novel variants such as U-Pen and U-Pen++. I presented research findings and brainstormed novel problems related to Medical Image Classification and Segmentation, including insights from Google DeepMind's research in Computer Vision and Deep Learning. This work significantly contributed to advancements in medical image segmentation techniques.

### üßë‚Äçüè´ Teaching Assistant
For the SAT5165 - Introduction to Big Data Analytics course taught by Prof. Xiaoyong (Brian) Yuan, I evaluated three major assignments for 50 students, providing detailed feedback and grading to enhance their understanding of Big Data concepts and tools. I conducted weekly one-hour sessions to assist students, developed installation guides and tutorials for Hadoop and Apache Spark, and fostered a supportive learning environment by providing feedback, guidance, and technical support. This role allowed me to help students successfully navigate complex technologies and improve their academic performance.


## üåê Socials:
[![LinkedIn](https://img.shields.io/badge/LinkedIn-%230077B5.svg?logo=linkedin&logoColor=white)](https://linkedin.com/in/ketansingh-patil) [![Medium](https://img.shields.io/badge/Medium-12100E?logo=medium&logoColor=white)](https://medium.com/@ketanp05) 

# üíª Tech Stack

# Computer Science Fundamentals
![Data Structures](https://img.shields.io/badge/Data%20Structures-%235C2D91.svg?style=for-the-badge&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mP8/wcAAwEB/SoA3e8PuB8AAAAASUVORK5CYII=&logoColor=white) ![Algorithms](https://img.shields.io/badge/Algorithms-%230052CC.svg?style=for-the-badge&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mP8/wcAAwEB/SoA3e8PuB8AAAAASUVORK5CYII=&logoColor=white) ![OOP](https://img.shields.io/badge/OOP-%23764ABC.svg?style=for-the-badge&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mP8/wcAAwEB/SoA3e8PuB8AAAAASUVORK5CYII=&logoColor=white) ![Distributed Systems](https://img.shields.io/badge/Distributed%20Systems-%2343853D.svg?style=for-the-badge&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mP8/wcAAwEB/SoA3e8PuB8AAAAASUVORK5CYII=&logoColor=white)

# Programming Languages
![HTML5](https://img.shields.io/badge/html5-%23E34F26.svg?style=for-the-badge&logo=html5&logoColor=white) ![CSS3](https://img.shields.io/badge/css3-%231572B6.svg?style=for-the-badge&logo=css3&logoColor=white) ![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) ![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black) ![C++](https://img.shields.io/badge/c++-%2300599C.svg?style=for-the-badge&logo=c%2B%2B&logoColor=white) 

# Data Engineering and Analytics
![SQL](https://img.shields.io/badge/SQL-4479A1.svg?style=for-the-badge&logo=amazon-dynamodb&logoColor=white)  ![Apache Spark](https://img.shields.io/badge/Apache%20Spark-FDEE21?style=for-the-badge&logo=apachespark&logoColor=black) ![Apache Hadoop](https://img.shields.io/badge/Apache%20Hadoop-66CCFF?style=for-the-badge&logo=apachehadoop&logoColor=black)  ![Apache Hive](https://img.shields.io/badge/Apache%20Hive-FDEE21?style=for-the-badge&logo=apachehive&logoColor=black) ![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white) ![Azure Databricks](https://img.shields.io/badge/Azure%20Databricks-FF3621.svg?style=for-the-badge&logo=databricks&logoColor=white) ![Denodo](https://img.shields.io/badge/Denodo-007DBA.svg?style=for-the-badge&logoColor=white) ![Tableau](https://img.shields.io/badge/Tableau-E97627.svg?style=for-the-badge&logo=tableau&logoColor=white) ![Excel](https://img.shields.io/badge/Excel-217346.svg?style=for-the-badge&logo=microsoft-excel&logoColor=white)

# Machine Learning
![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white) ![NumPy](https://img.shields.io/badge/NumPy-013243.svg?style=for-the-badge&logo=numpy&logoColor=white) ![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black) ![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00.svg?style=for-the-badge&logo=tensorflow&logoColor=white) ![Keras](https://img.shields.io/badge/Keras-D00000.svg?style=for-the-badge&logo=Keras&logoColor=white) ![CNN](https://img.shields.io/badge/CNN-FF6F00.svg?style=for-the-badge&logo=Kaggle&logoColor=white)

# Cloud
![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white)  ![Azure](https://img.shields.io/badge/azure-%230072C6.svg?style=for-the-badge&logo=microsoftazure&logoColor=white) 

# Web Development
![Flask](https://img.shields.io/badge/flask-%23000.svg?style=for-the-badge&logo=flask&logoColor=white) ![FastAPI](https://img.shields.io/badge/FastAPI-009688.svg?style=for-the-badge&logo=fastapi&logoColor=white) ![React](https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB) ![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=nextdotjs&logoColor=white) ![Express](https://img.shields.io/badge/Express-000000?style=for-the-badge&logo=express&logoColor=white) ![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)

# Databases
![MicrosoftSQLServer](https://img.shields.io/badge/Microsoft%20SQL%20Server-CC2927?style=for-the-badge&logo=microsoft%20sql%20server&logoColor=white)  ![MongoDB](https://img.shields.io/badge/MongoDB-%234ea94b.svg?style=for-the-badge&logo=mongodb&logoColor=white)  ![MySQL](https://img.shields.io/badge/mysql-%2300000f.svg?style=for-the-badge&logo=mysql&logoColor=white) ![SQLite](https://img.shields.io/badge/sqlite-%2307405e.svg?style=for-the-badge&logo=sqlite&logoColor=white) ![PostgreSQL](https://img.shields.io/badge/PostgreSQL-336791.svg?style=for-the-badge&logo=postgresql&logoColor=white)

# Tools
![REST API](https://img.shields.io/badge/REST%20API-FF6C37?style=for-the-badge&logo=rest-api&logoColor=white) ![Linux](https://img.shields.io/badge/Linux-FCC624.svg?style=for-the-badge&logo=linux&logoColor=black) ![Git](https://img.shields.io/badge/Git-F05032.svg?style=for-the-badge&logo=git&logoColor=white) ![GitHub Actions](https://img.shields.io/badge/GitHub%20Actions-2088FF?style=for-the-badge&logo=github-actions&logoColor=white) ![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)  ![Grafana](https://img.shields.io/badge/grafana-F46800.svg?style=for-the-badge&logo=grafana&logoColor=white&color=%23F46800)  ![Shell Script](https://img.shields.io/badge/shell_script-%23121011.svg?style=for-the-badge&logo=gnu-bash&logoColor=white)  ![YAML](https://img.shields.io/badge/YAML-0B1C2C.svg?style=for-the-badge&logo=yaml&logoColor=white) ![JSON](https://img.shields.io/badge/JSON-000000.svg?style=for-the-badge&logo=json&logoColor=white) ![Postman](https://img.shields.io/badge/Postman-FF6C37?style=for-the-badge&logo=postman&logoColor=white) ![Confluence](https://img.shields.io/badge/confluence-%23172BF4.svg?style=for-the-badge&logo=confluence&logoColor=white)  ![Jira](https://img.shields.io/badge/jira-%230A0FFF.svg?style=for-the-badge&logo=jira&logoColor=white) ![Trello](https://img.shields.io/badge/Trello-%23026AA7.svg?style=for-the-badge&logo=Trello&logoColor=white)

# üìä GitHub Stats
![](https://github-readme-stats.vercel.app/api?username=ketanp05&theme=dark&hide_border=false&include_all_commits=false&count_private=false)<br/>
![](https://github-readme-streak-stats.herokuapp.com/?user=ketanp05&theme=dark&hide_border=false)<br/>
![](https://github-readme-stats.vercel.app/api/top-langs/?username=ketanp05&theme=dark&hide_border=false&include_all_commits=false&count_private=false&layout=compact)

## üèÜ GitHub Trophies
![](https://github-profile-trophy.vercel.app/?username=ketanp05&theme=radical&no-frame=false&no-bg=true&margin-w=4)

### ‚úçÔ∏è Random Dev Quote
![](https://quotes-github-readme.vercel.app/api?type=horizontal&theme=radical)

### üîù Top Contributed Repo
![](https://github-contributor-stats.vercel.app/api?username=ketanp05&limit=5&theme=dark&combine_all_yearly_contributions=true)

---
[![](https://visitcount.itsvg.in/api?id=ketanp05&icon=0&color=0)](https://visitcount.itsvg.in)

  ## üí∞ You can help me by Donating
  [![PayPal](https://img.shields.io/badge/PayPal-00457C?style=for-the-badge&logo=paypal&logoColor=white)](https://paypal.me/ketanp05) 

  
<!-- Proudly created with GPRM ( https://gprm.itsvg.in ) -->
